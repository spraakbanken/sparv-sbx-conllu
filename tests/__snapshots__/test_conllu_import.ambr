# serializer version: 1
# name: test_analyze_conllu[assets/texts/empty-node.conllu]
  set({
    'document',
    'sentence',
    'text',
    'token',
    'token:baseform',
  })
# ---
# name: test_analyze_conllu[assets/texts/en_ewt-ud-test_excerp.conllu]
  set({
    'document',
    'document:id',
    'paragraph',
    'paragraph:id',
    'sentence',
    'sentence:sent_id',
    'text',
    'token',
    'token:baseform',
    'token:dephead_ud',
    'token:deprel_ud',
    'token:deps_ud',
    'token:feats_ud',
    'token:misc_ud',
    'token:pos_ud',
    'token:xpos',
  })
# ---
# name: test_analyze_conllu[assets/texts/long-token-to-text.conllu]
  set({
    'document',
    'sentence',
    'sentence:sent_id',
    'text',
    'token',
    'token:baseform',
    'token:dephead_ud',
    'token:deprel_ud',
    'token:deps_ud',
    'token:feats_ud',
    'token:misc_ud',
    'token:pos_ud',
    'token:xpos',
  })
# ---
# name: test_analyze_conllu[assets/texts/multiword.conllu]
  set({
    'document',
    'sentence',
    'text',
    'token',
    'token:baseform',
  })
# ---
# name: test_analyze_conllu[assets/texts/paragraph-and-document.conllu]
  set({
    'document',
    'document:id',
    'paragraph',
    'paragraph:id',
    'sentence',
    'sentence:sent_id',
    'text',
    'token',
    'token:baseform',
    'token:dephead_ud',
    'token:deprel_ud',
    'token:feats_ud',
    'token:misc_ud',
    'token:pos_ud',
    'token:xpos',
  })
# ---
# name: test_analyze_conllu[assets/texts/paragraph-in-sentence.conllu]
  set({
    'document',
    'paragraph',
    'sentence',
    'sentence:sent_id',
    'text',
    'token',
    'token:baseform',
    'token:dephead_ud',
    'token:deprel_ud',
    'token:misc_ud',
    'token:pos_ud',
  })
# ---
# name: test_analyze_conllu[assets/texts/sentence-comments.conllu]
  set({
    'document',
    'sentence',
    'sentence:sent_id',
    'text',
    'token',
    'token:baseform',
    'token:dephead_ud',
    'token:deprel_ud',
    'token:deps_ud',
    'token:feats_ud',
    'token:misc_ud',
    'token:pos_ud',
    'token:xpos',
  })
# ---
# name: test_analyze_conllu[assets/texts/space-after-no.conllu]
  set({
    'document',
    'sentence',
    'text',
    'token',
    'token:baseform',
    'token:misc_ud',
    'token:pos_ud',
  })
# ---
# name: test_find_root
  Token({
    'deprel': 'nsubj',
    'feats': None,
    'form': 'B',
    'head': 4,
    'id': 2,
    'lemma': 'B',
    'upos': 'NOUN',
    'xpos': None,
  })
# ---
# name: test_find_root.1
  Token({
    'deprel': 'case',
    'feats': None,
    'form': 'C',
    'head': 4,
    'id': 3,
    'lemma': 'C',
    'upos': 'PART',
    'xpos': None,
  })
# ---
# name: test_find_root.2
  Token({
    'deprel': 'root',
    'feats': None,
    'form': 'C',
    'head': 0,
    'id': 3,
    'lemma': 'C',
    'upos': 'PART',
    'xpos': None,
  })
# ---
# name: test_parse[empty-node]
  _CallList([
    _Call(
      tuple(
        'Sue likes coffee and Bill tea ',
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[empty-node].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'paragraph',
          'sentence',
          'sentence',
          'text',
          'token',
          'token:baseform',
          'token:id',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[en_ewt-ud-test_excerp]
  _CallList([
    _Call(
      tuple(
        "What if Google Morphed Into GoogleOS? What if Google expanded on its search-engine (and now e-mail) wares into a full-fledged operating system? [via Microsoft Watch from Mary Jo Foley ] (And, by the way, is anybody else just a little nostalgic for the days when that was a good thing?) This BuzzMachine post argues that Google's rush toward ubiquity might backfire -- which we've all heard before, but it's particularly well-put in this post. Google is a nice search engine. Does anybody use it for anything else? They own blogger, of course. Is that a money maker? I'm staying away from the stock.",
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[en_ewt-ud-test_excerp].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'document:id',
          'paragraph',
          'paragraph:id',
          'sentence',
          'sentence',
          'sentence:sent_id',
          'text',
          'token',
          'token:baseform',
          'token:dephead_ud',
          'token:deprel_ud',
          'token:deps_ud',
          'token:feats_ud',
          'token:id',
          'token:misc_ud',
          'token:pos_ud',
          'token:xpos',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[long-token-to-text]
  _CallList([
    _Call(
      tuple(
        'Moodymanni ehk Kenny Dixon Jnr võid näha ja lausa liigutamas aadressil proto.groovetech.com/mk-demf.rxml?file=/demf/mainstage/day2/mainstageday2-kennydixonjr.rm (Antes Edition) Filmimuusika loomine on mitmes mõttes erinev kontserdisaalis ette kantava teose kirjutamisest, sisaldades nii kitsendusi kui ka ahvatlevaid võimalusi.',
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[long-token-to-text].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'paragraph',
          'sentence',
          'sentence',
          'sentence:sent_id',
          'text',
          'token',
          'token:baseform',
          'token:dephead_ud',
          'token:deprel_ud',
          'token:deps_ud',
          'token:feats_ud',
          'token:id',
          'token:misc_ud',
          'token:pos_ud',
          'token:xpos',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[multiword]
  _CallList([
    _Call(
      tuple(
        'vámonos al mar ',
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[multiword].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'paragraph',
          'sentence',
          'sentence',
          'text',
          'token',
          'token:baseform',
          'token:id',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[paragraph-and-document]
  _CallList([
    _Call(
      tuple(
        'Slovenská ústava: pro i proti',
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[paragraph-and-document].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'document:id',
          'paragraph',
          'paragraph:id',
          'sentence',
          'sentence',
          'sentence:sent_id',
          'sentence:text_en',
          'text',
          'token',
          'token:baseform',
          'token:dephead_ud',
          'token:deprel_ud',
          'token:feats_ud',
          'token:id',
          'token:misc_ud',
          'token:pos_ud',
          'token:xpos',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[paragraph-in-sentence]
  _CallList([
    _Call(
      tuple(
        'På högstadiet skall varje elev välja ett av fyra tillvalsämnen: * språk (franska eller tyska) * ekonomi * teknik * konst',
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[paragraph-in-sentence].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'paragraph',
          'sentence',
          'sentence',
          'sentence:sent_id',
          'text',
          'token',
          'token:baseform',
          'token:dephead_ud',
          'token:deprel_ud',
          'token:id',
          'token:misc_ud',
          'token:pos_ud',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[sentence-comments]
  _CallList([
    _Call(
      tuple(
        'They buy and sell books. I have no clue. तत् यथानुश्रूयते।',
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[sentence-comments].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'paragraph',
          'sentence',
          'sentence',
          'sentence:sent_id',
          'sentence:text_en',
          'sentence:text_fr',
          'sentence:translit',
          'text',
          'token',
          'token:baseform',
          'token:dephead_ud',
          'token:deprel_ud',
          'token:deps_ud',
          'token:feats_ud',
          'token:id',
          'token:misc_ud',
          'token:pos_ud',
          'token:xpos',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[space-after-no]
  _CallList([
    _Call(
      tuple(
        'Er arbeitet fürs FBI (deutsch etwa: „Bundesamt für Ermittlung“). ',
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parse[space-after-no].1
  _CallList([
    _Call(
      tuple(
        list([
          'document',
          'paragraph',
          'sentence',
          'sentence',
          'text',
          'token',
          'token:baseform',
          'token:deprel_ud',
          'token:id',
          'token:misc_ud',
          'token:pos_ud',
        ]),
      ),
      dict({
      }),
    ),
  ])
# ---
# name: test_parser_parse
  defaultdict({
    'document': dict({
      'attrs': set({
      }),
      'elements': list([
        dict({
          'attrs': dict({
          }),
          'end': tuple(
            23,
            4,
          ),
          'name': 'document',
          'start': tuple(
            0,
            1,
          ),
        }),
      ]),
    }),
    'paragraph': dict({
      'attrs': set({
      }),
      'elements': list([
      ]),
    }),
    'sentence': dict({
      'attrs': set({
        'sent_id',
      }),
      'elements': list([
        dict({
          'attrs': dict({
            'sent_id': 'easy case',
          }),
          'end': tuple(
            7,
            2,
          ),
          'name': 'sentence',
          'start': tuple(
            0,
            3,
          ),
        }),
        dict({
          'attrs': dict({
            'sent_id': 'easy case (flipped)',
          }),
          'end': tuple(
            15,
            2,
          ),
          'name': 'sentence',
          'start': tuple(
            8,
            3,
          ),
        }),
        dict({
          'attrs': dict({
            'sent_id': 'tricky case 1',
          }),
          'end': tuple(
            23,
            2,
          ),
          'name': 'sentence',
          'start': tuple(
            16,
            3,
          ),
        }),
      ]),
    }),
    'token': dict({
      'attrs': set({
        'baseform',
        'dephead_ud',
        'deprel_ud',
        'id',
        'pos_ud',
      }),
      'elements': list([
        dict({
          'attrs': dict({
            'baseform': 'A',
            'dephead_ud': 0,
            'deprel_ud': 'root',
            'id': '1',
            'pos_ud': 'VERB',
          }),
          'end': tuple(
            1,
            0,
          ),
          'name': 'token',
          'start': tuple(
            0,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'B',
            'dephead_ud': 4,
            'deprel_ud': 'nsubj',
            'id': '2',
            'pos_ud': 'NOUN',
          }),
          'end': tuple(
            4,
            0,
          ),
          'name': 'token',
          'start': tuple(
            2,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'D',
            'dephead_ud': 1,
            'deprel_ud': 'nsubj',
            'id': '4',
            'pos_ud': 'NOUN',
          }),
          'end': tuple(
            6,
            0,
          ),
          'name': 'token',
          'start': tuple(
            5,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'A',
            'dephead_ud': 0,
            'deprel_ud': 'root',
            'id': '1',
            'pos_ud': 'VERB',
          }),
          'end': tuple(
            9,
            0,
          ),
          'name': 'token',
          'start': tuple(
            8,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'C',
            'dephead_ud': 4,
            'deprel_ud': 'case',
            'id': '3',
            'pos_ud': 'PART',
          }),
          'end': tuple(
            12,
            0,
          ),
          'name': 'token',
          'start': tuple(
            10,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'D',
            'dephead_ud': 1,
            'deprel_ud': 'nsubj',
            'id': '4',
            'pos_ud': 'NOUN',
          }),
          'end': tuple(
            14,
            0,
          ),
          'name': 'token',
          'start': tuple(
            13,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'A',
            'dephead_ud': 3,
            'deprel_ud': 'nsubj',
            'id': '1',
            'pos_ud': 'DET',
          }),
          'end': tuple(
            17,
            0,
          ),
          'name': 'token',
          'start': tuple(
            16,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'C',
            'dephead_ud': 0,
            'deprel_ud': 'root',
            'id': '3',
            'pos_ud': 'PART',
          }),
          'end': tuple(
            20,
            0,
          ),
          'name': 'token',
          'start': tuple(
            18,
            5,
          ),
        }),
        dict({
          'attrs': dict({
            'baseform': 'D',
            'dephead_ud': 3,
            'deprel_ud': 'punct',
            'id': '4',
            'pos_ud': 'PUNCT',
          }),
          'end': tuple(
            22,
            0,
          ),
          'name': 'token',
          'start': tuple(
            21,
            5,
          ),
        }),
      ]),
    }),
  })
# ---
